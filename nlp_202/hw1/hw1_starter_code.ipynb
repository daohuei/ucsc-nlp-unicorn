{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 11231,
     "status": "ok",
     "timestamp": 1643321069183,
     "user": {
      "displayName": "Changmao Li",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhiHbvXZPEBo5KzJECaSn606PYoH_L4ymcFL5Qm=s64",
      "userId": "13158050113440428318"
     },
     "user_tz": 480
    },
    "id": "lffFsqA8BbFV"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ken/.local/lib/python3.8/site-packages/torch/cuda/__init__.py:80: UserWarning: CUDA initialization: CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero. (Triggered internally at  ../c10/cuda/CUDAFunctions.cpp:112.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchtext.legacy import data\n",
    "\n",
    "SEED = 1234\n",
    "\n",
    "torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "TEXT = data.Field(tokenize = 'spacy',\n",
    "                  tokenizer_language = 'en_core_web_sm')\n",
    "LABEL = data.LabelField(dtype = torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 124879,
     "status": "ok",
     "timestamp": 1643321196162,
     "user": {
      "displayName": "Changmao Li",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhiHbvXZPEBo5KzJECaSn606PYoH_L4ymcFL5Qm=s64",
      "userId": "13158050113440428318"
     },
     "user_tz": 480
    },
    "id": "IatXWViqB3Pi",
    "outputId": "a92ba1ef-04fa-4d0f-d56a-444722572028"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples: 25000\n",
      "Number of testing examples: 25000\n",
      "{'text': ['\"', 'Rich', 'in', 'Love', '\"', 'is', 'a', 'slice', '-', 'of', '-', 'life', 'film', 'which', 'takes', 'the', 'viewer', 'into', 'the', 'goings', 'on', 'of', 'a', 'somewhat', 'quirky', 'Charleston', ',', 'SC', 'family', '.', 'Highly', 'romanticized', ',', 'beautifully', 'shot', ',', 'well', 'written', 'and', 'acted', ',', '\"', 'RIL', '\"', 'washes', 'over', 'you', 'like', 'a', 'summer', 'breeze', 'as', 'its', 'plotless', 'meandering', 'breathes', 'life', 'into', 'the', 'characters', 'such', 'that', 'at', 'film', \"'s\", 'end', 'you', \"'ll\", 'feel', 'like', 'an', 'old', 'friend', 'of', 'the', 'family.<br', '/><br', '/>A', 'wonderfully', 'crafted', 'character', '-', 'driven', 'film', 'from', 'the', 'director', 'of', '\"', 'Driving', 'Miss', 'Daisy', '\"', ',', '\"', 'RIL', '\"', 'is', 'a', 'somewhat', 'obscure', 'little', '\"', 'sleeper', '\"', 'which', 'will', 'appeal', 'most', 'to', 'mature', 'audiences', '.'], 'label': 'pos'}\n"
     ]
    }
   ],
   "source": [
    "from torchtext.legacy import datasets\n",
    "\n",
    "train_data, test_data = datasets.IMDB.splits(TEXT, LABEL)\n",
    "print(f'Number of training examples: {len(train_data)}')\n",
    "print(f'Number of testing examples: {len(test_data)}')\n",
    "print(vars(train_data.examples[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 136,
     "status": "ok",
     "timestamp": 1643321302399,
     "user": {
      "displayName": "Changmao Li",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhiHbvXZPEBo5KzJECaSn606PYoH_L4ymcFL5Qm=s64",
      "userId": "13158050113440428318"
     },
     "user_tz": 480
    },
    "id": "4RnxEJ0RB3-J",
    "outputId": "3338d0a6-0089-45bc-c8e0-b5d0a634a4ca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples: 17500\n",
      "Number of validation examples: 7500\n",
      "Number of testing examples: 25000\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "train_data, valid_data = train_data.split(random_state = random.seed(SEED))\n",
    "print(f'Number of training examples: {len(train_data)}')\n",
    "print(f'Number of validation examples: {len(valid_data)}')\n",
    "print(f'Number of testing examples: {len(test_data)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1210,
     "status": "ok",
     "timestamp": 1641517880002,
     "user": {
      "displayName": "Changmao Li",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhiHbvXZPEBo5KzJECaSn606PYoH_L4ymcFL5Qm=s64",
      "userId": "13158050113440428318"
     },
     "user_tz": 480
    },
    "id": "xtSufWSGB_bw",
    "outputId": "35b65f53-e69e-458a-806a-8d381d2db8a7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 25002\n",
      "Unique tokens in LABEL vocabulary: 2\n",
      "[('the', 202292), (',', 192366), ('.', 166236), ('a', 109737), ('and', 109602), ('of', 100866), ('to', 93857), ('is', 76621), ('in', 61539), ('I', 54351), ('it', 53589), ('that', 49151), ('\"', 43941), (\"'s\", 43540), ('this', 42430), ('-', 37794), ('/><br', 35757), ('was', 34791), ('as', 30696), ('with', 30187)]\n",
      "['<unk>', '<pad>', 'the', ',', '.', 'a', 'and', 'of', 'to', 'is']\n",
      "defaultdict(None, {'neg': 0, 'pos': 1})\n"
     ]
    }
   ],
   "source": [
    "MAX_VOCAB_SIZE = 25_000\n",
    "\n",
    "TEXT.build_vocab(train_data, max_size = MAX_VOCAB_SIZE)\n",
    "LABEL.build_vocab(train_data)\n",
    "print(f\"Unique tokens in TEXT vocabulary: {len(TEXT.vocab)}\")\n",
    "print(f\"Unique tokens in LABEL vocabulary: {len(LABEL.vocab)}\")\n",
    "print(TEXT.vocab.freqs.most_common(20))\n",
    "print(TEXT.vocab.itos[:10])\n",
    "print(LABEL.vocab.stoi)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# Do not use BucketIterator in your implementation because you are required to implement the padding and masking yourself.\n",
    "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits((train_data, valid_data, test_data), batch_size=1, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "id": "nI_gFLUXCEdY"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "class LR(nn.Module):\n",
    "    def __init__(self, input_dim, embedding_dim, output_dim):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(input_dim, embedding_dim)\n",
    "        self.fc = nn.Linear(embedding_dim, output_dim)\n",
    "    def forward(self, text):\n",
    "        embedded = self.embedding(text).squeeze().sum(0)\n",
    "        return self.fc(embedded)\n",
    "    \n",
    "# define LSTM Classifier model class\n",
    "class LSTMClassifier(nn.Module):\n",
    "    def __init__(self, input_dim, embedding_dim, output_dim, hidden_dim):\n",
    "        super().__init__()\n",
    "        # the word vector for index 0 will be set to zero\n",
    "        self.embedding = nn.Embedding(\n",
    "            input_dim, embedding_dim, padding_idx=0\n",
    "        )\n",
    "        # LSTM layer\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim)\n",
    "        self.fc = nn.Linear(\n",
    "            hidden_dim, output_dim\n",
    "        )\n",
    "\n",
    "    def forward(self, text, lens):\n",
    "\n",
    "        embedded = self.embedding(text)\n",
    "        embedded = pack_padded_sequence(\n",
    "            embedded, lens, enforce_sorted=False\n",
    "        )\n",
    "        out, h_n = self.lstm(embedded)\n",
    "        out, seq_lengths = pad_packed_sequence(\n",
    "            out\n",
    "        )\n",
    "        \n",
    "        out = torch.stack(\n",
    "            [torch.mean(out[:length.item(), i, :], 0) for i, length in enumerate(lens)]\n",
    "        )\n",
    "\n",
    "        return self.fc(out).squeeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "id": "-lZ2obDVDmEl"
   },
   "outputs": [],
   "source": [
    "INPUT_DIM = len(TEXT.vocab)\n",
    "EMBEDDING_DIM = 100\n",
    "OUTPUT_DIM = 1\n",
    "\n",
    "lr_model = LR(INPUT_DIM, EMBEDDING_DIM, OUTPUT_DIM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIM = len(TEXT.vocab)\n",
    "EMBEDDING_DIM = 100\n",
    "OUTPUT_DIM = 1\n",
    "HIDDEN_DIM = 4\n",
    "\n",
    "lstm_model = LSTMClassifier(INPUT_DIM, EMBEDDING_DIM, OUTPUT_DIM, HIDDEN_DIM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1641518691062,
     "user": {
      "displayName": "Changmao Li",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhiHbvXZPEBo5KzJECaSn606PYoH_L4ymcFL5Qm=s64",
      "userId": "13158050113440428318"
     },
     "user_tz": 480
    },
    "id": "eJ6_rLRuK2l7",
    "outputId": "ce464ac9-7c86-4b94-88ad-8e101c8f5892"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The LR model has 2,500,301 trainable parameters\n",
      "The LSTM model has 2,501,901 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'The LR model has {count_parameters(lr_model):,} trainable parameters')\n",
    "print(f'The LSTM model has {count_parameters(lstm_model):,} trainable parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "id": "IbufnJzvLAlf"
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "lr_optimizer = optim.SGD(lr_model.parameters(), lr=1e-3)\n",
    "lstm_optimizer = optim.SGD(lstm_model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "id": "I1fHORT8LBOK"
   },
   "outputs": [],
   "source": [
    "lr_criterion = nn.BCEWithLogitsLoss()\n",
    "lstm_criterion = nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "id": "z3gdBHHULC7y"
   },
   "outputs": [],
   "source": [
    "lr_model = lr_model.to(device)\n",
    "lr_criterion = lr_criterion.to(device)\n",
    "\n",
    "lstm_model = lstm_model.to(device)\n",
    "lstm_criterion = lstm_criterion.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "id": "KF2EdETnLEwt"
   },
   "outputs": [],
   "source": [
    "def binary_accuracy(preds, y):\n",
    "    \"\"\"\n",
    "    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n",
    "    \"\"\"\n",
    "\n",
    "    #round predictions to the closest integer\n",
    "    rounded_preds = torch.round(torch.sigmoid(preds))\n",
    "    correct = (rounded_preds == y).float() #convert into float for division \n",
    "    acc = correct.sum() / len(correct)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "id": "2o9l76H5LGm9"
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "def train(model, iterator, optimizer, criterion, is_lstm=False):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for instance in tqdm(iterator, desc=\"Training...\", total=len(iterator)):\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        predictions = []\n",
    "        if is_lstm:\n",
    "            predictions = model(instance.text, torch.Tensor([len(instance.text)]).int())\n",
    "        else:\n",
    "            predictions = model(instance.text)\n",
    "        \n",
    "        loss = criterion(predictions, instance.label)\n",
    "        \n",
    "        acc = binary_accuracy(predictions, instance.label)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "id": "bBwRhOrzLKSH"
   },
   "outputs": [],
   "source": [
    "def evaluate(model, iterator, criterion, is_lstm=False):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "    \n",
    "        for instance in tqdm(iterator, desc=\"Evaluating...\", total=len(iterator)):\n",
    "        \n",
    "            predictions = []\n",
    "            if is_lstm:\n",
    "                predictions = model(instance.text, torch.Tensor([len(instance.text)]).int())\n",
    "            else:\n",
    "                predictions = model(instance.text)\n",
    "            \n",
    "            loss = criterion(predictions, instance.label)\n",
    "            \n",
    "            acc = binary_accuracy(predictions, instance.label)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "id": "FOHkN5P5LMtl"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 205631,
     "status": "ok",
     "timestamp": 1641518953426,
     "user": {
      "displayName": "Changmao Li",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhiHbvXZPEBo5KzJECaSn606PYoH_L4ymcFL5Qm=s64",
      "userId": "13158050113440428318"
     },
     "user_tz": 480
    },
    "id": "63EPftxxLOxH",
    "outputId": "c9b3ed74-e36e-4969-ea5d-476a6d7051cf"
   },
   "outputs": [],
   "source": [
    "N_EPOCHS = 5\n",
    "\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "\n",
    "    start_time = time.time()\n",
    "    \n",
    "    train_loss, train_acc = train(lr_model, train_iterator, lr_optimizer, lr_criterion)\n",
    "    valid_loss, valid_acc = evaluate(lr_model, valid_iterator, lr_criterion)\n",
    "    \n",
    "    end_time = time.time()\n",
    "\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "    \n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), 'lr-starter-model.pt')\n",
    "    \n",
    "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
    "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...: 100%|██████████| 17500/17500 [14:28<00:00, 20.15it/s]\n",
      "Evaluating...: 100%|██████████| 7500/7500 [00:56<00:00, 133.61it/s]\n",
      "Training...:   0%|          | 3/17500 [00:00<10:13, 28.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Epoch Time: 15m 24s\n",
      "\tTrain Loss: 0.694 | Train Acc: 51.94%\n",
      "\t Val. Loss: 0.692 |  Val. Acc: 53.49%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...: 100%|██████████| 17500/17500 [14:35<00:00, 20.00it/s]\n",
      "Evaluating...: 100%|██████████| 7500/7500 [01:00<00:00, 124.46it/s]\n",
      "Training...:   0%|          | 2/17500 [00:00<15:27, 18.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 02 | Epoch Time: 15m 35s\n",
      "\tTrain Loss: 0.692 | Train Acc: 53.89%\n",
      "\t Val. Loss: 0.692 |  Val. Acc: 53.93%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...:   1%|          | 151/17500 [00:08<15:22, 18.81it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-229-7a821bb7e4ce>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlstm_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_iterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlstm_optimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlstm_criterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_lstm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mvalid_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlstm_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_iterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlstm_criterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_lstm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-226-a5cf454809d4>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, iterator, optimizer, criterion, is_lstm)\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbinary_accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minstance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    305\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 307\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    152\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[1;32m    155\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "N_EPOCHS = 5\n",
    "\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "\n",
    "    start_time = time.time()\n",
    "    \n",
    "    train_loss, train_acc = train(lstm_model, train_iterator, lstm_optimizer, lstm_criterion, is_lstm=True)\n",
    "    valid_loss, valid_acc = evaluate(lstm_model, valid_iterator, lstm_criterion, is_lstm=True)\n",
    "    \n",
    "    end_time = time.time()\n",
    "\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "    \n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(lstm_model.state_dict(), 'lstm-starter-model.pt')\n",
    "    \n",
    "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
    "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 18888,
     "status": "ok",
     "timestamp": 1641518975934,
     "user": {
      "displayName": "Changmao Li",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhiHbvXZPEBo5KzJECaSn606PYoH_L4ymcFL5Qm=s64",
      "userId": "13158050113440428318"
     },
     "user_tz": 480
    },
    "id": "s2vQBjeTLTTv",
    "outputId": "e767d8c6-ce03-4e15-b0c3-60c6f851c349"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating...: 100%|██████████| 25000/25000 [03:18<00:00, 125.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.692 | Test Acc: 54.38%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "lstm_model.load_state_dict(torch.load('lstm-starter-model.pt'))\n",
    "\n",
    "test_loss, test_acc = evaluate(lstm_model, test_iterator, lstm_criterion, is_lstm=True)\n",
    "\n",
    "print(f'Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 155,
     "status": "ok",
     "timestamp": 1641519323133,
     "user": {
      "displayName": "Changmao Li",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhiHbvXZPEBo5KzJECaSn606PYoH_L4ymcFL5Qm=s64",
      "userId": "13158050113440428318"
     },
     "user_tz": 480
    },
    "id": "Ev4idwpONzs9",
    "outputId": "369fb192-fa2a-4b55-934f-7396f401efd3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-6.7634], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor([0.5967], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor([5.0447], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor([-0.4295], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor([7.1855], device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Test of model correctness\n",
    "max_n_test_instances = 5\n",
    "i = 1\n",
    "for instance in valid_iterator:\n",
    "  score = model(instance.text)\n",
    "  print(score)\n",
    "  if i >= max_n_test_instances:\n",
    "    break\n",
    "  else:\n",
    "    i += 1\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "hw1_starter_code.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
