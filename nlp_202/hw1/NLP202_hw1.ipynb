{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "lffFsqA8BbFV"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchtext.legacy import data\n",
    "\n",
    "SEED = 1234\n",
    "# same seed generator\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "# to make sure input output are fixed/deterministic\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "# load the text with spacy tokenization (in English)\n",
    "TEXT = data.Field(tokenize=\"spacy\", tokenizer_language=\"en_core_web_sm\")\n",
    "# the label type is float\n",
    "LABEL = data.LabelField(dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IatXWViqB3Pi",
    "outputId": "2cfd8957-0979-45ce-db24-00035eaeda96"
   },
   "outputs": [],
   "source": [
    "from torchtext.legacy import datasets\n",
    "\n",
    "# load the IMDB dataset\n",
    "train_data, test_data = datasets.IMDB.splits(TEXT, LABEL)\n",
    "print(f\"Number of training examples: {len(train_data)}\")\n",
    "print(f\"Number of testing examples: {len(test_data)}\")\n",
    "print(vars(train_data.examples[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4RnxEJ0RB3-J",
    "outputId": "4b0c3fbf-fd74-4dcd-c18f-fefe273368ca"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "# split the data into train set and valid set with random seed\n",
    "train_data, valid_data = train_data.split(random_state=random.seed(SEED))\n",
    "print(f\"Number of training examples: {len(train_data)}\")\n",
    "print(f\"Number of validation examples: {len(valid_data)}\")\n",
    "print(f\"Number of testing examples: {len(test_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xtSufWSGB_bw",
    "outputId": "2c4a6c40-d30d-453f-ee53-21b10e6487b2"
   },
   "outputs": [],
   "source": [
    "MAX_VOCAB_SIZE = 25000\n",
    "\n",
    "# build the vocab with given max vocab size\n",
    "TEXT.build_vocab(train_data, max_size=MAX_VOCAB_SIZE)\n",
    "LABEL.build_vocab(train_data)\n",
    "# switching the <pad> and <unk>, since we need <pad> to be 0 index\n",
    "TEXT.vocab = TEXT.vocab_cls(\n",
    "    TEXT.vocab.freqs, max_size=MAX_VOCAB_SIZE, specials=[\"<pad>\", \"<unk>\"]\n",
    ")\n",
    "print(f\"Unique tokens in TEXT vocabulary: {len(TEXT.vocab)}\")\n",
    "print(f\"Unique tokens in LABEL vocabulary: {len(LABEL.vocab)}\")\n",
    "print(TEXT.vocab.itos)\n",
    "# print(TEXT.vocab.freqs.most_common(20))\n",
    "# print(TEXT.vocab.itos[:10])\n",
    "# print(LABEL.vocab.stoi)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# Do not use BucketIterator in your implementation because you are required to implement the padding and masking yourself.\n",
    "# TODO: implementing padding and masking\n",
    "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n",
    "    (train_data, valid_data, test_data), batch_size=1, device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xpCNHEZKghXf"
   },
   "outputs": [],
   "source": [
    "# define the mini-batch size => tunable\n",
    "batch_size = 4\n",
    "\n",
    "# train_iter, test_iter = train_data.iters(batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "biNcg6lKMOsz"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DZAM3t-1d9fq"
   },
   "outputs": [],
   "source": [
    "# label preprocess pipeline\n",
    "def label_pipeline(label):\n",
    "    return LABEL.vocab.stoi[label]\n",
    "\n",
    "\n",
    "# text preprocess pipeline\n",
    "def text_pipeline(text):\n",
    "    return [TEXT.vocab.stoi[token] for token in text]\n",
    "\n",
    "\n",
    "# preprocess batch data before loading each batch\n",
    "def collate_batch(batch):\n",
    "    label_list, text_list = [], []\n",
    "    for example in batch:\n",
    "        _label, _text = example.label, example.text\n",
    "        label_list.append(label_pipeline(_label))\n",
    "        processed_text = torch.tensor(text_pipeline(_text), dtype=torch.int64)\n",
    "        text_list.append(processed_text)\n",
    "    label_list = torch.tensor(label_list, dtype=torch.int64)\n",
    "    text_list = pad_sequence(text_list, batch_first=True)\n",
    "    return text_list.to(device), label_list.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wJlLJJejpyEy"
   },
   "outputs": [],
   "source": [
    "train_loader = DataLoader(\n",
    "    dataset=train_data, batch_size=batch_size, shuffle=True, collate_fn=collate_batch\n",
    ")\n",
    "valid_loader = DataLoader(\n",
    "    dataset=valid_data, batch_size=batch_size, shuffle=True, collate_fn=collate_batch\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-B8n6cmbf7vW"
   },
   "outputs": [],
   "source": [
    "# from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x_98KiuaejMp"
   },
   "outputs": [],
   "source": [
    "# seq = torch.tensor([[1,2,0], [3,0,0], [4,5,6]])\n",
    "# lens = [2, 1, 3]\n",
    "# packed = pack_padded_sequence(seq, lens, batch_first=True, enforce_sorted=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nI_gFLUXCEdY"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class LR(nn.Module):\n",
    "    def __init__(self, input_dim, embedding_dim, output_dim):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(input_dim, embedding_dim)\n",
    "        self.fc = nn.Linear(embedding_dim, output_dim)\n",
    "\n",
    "    def forward(self, text):\n",
    "        embedded = self.embedding(text).squeeze().sum(0)\n",
    "        return self.fc(embedded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S1Zq13m9snI1"
   },
   "outputs": [],
   "source": [
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-lZ2obDVDmEl",
    "outputId": "c1e99a9b-899e-4128-ea20-4cc19f94d2af"
   },
   "outputs": [],
   "source": [
    "INPUT_DIM = len(TEXT.vocab)\n",
    "EMBEDDING_DIM = 100\n",
    "OUTPUT_DIM = 1\n",
    "\n",
    "# vocab_len x 100 x 1 => a binary LR classifier\n",
    "model_single_instance = LR(INPUT_DIM, EMBEDDING_DIM, OUTPUT_DIM)\n",
    "model_mini_batch = LR(INPUT_DIM, EMBEDDING_DIM, OUTPUT_DIM)\n",
    "\n",
    "model_mini_batch.load_state_dict(copy.deepcopy(model_single_instance.state_dict()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eJ6_rLRuK2l7",
    "outputId": "aeb34113-e0d9-4441-ab15-4769c89c76ef"
   },
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "\n",
    "print(f\"The model has {count_parameters(model_single_instance):,} trainable parameters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IbufnJzvLAlf"
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "optimizer_si = optim.SGD(model_single_instance.parameters(), lr=1e-3)\n",
    "optimizer_mb = optim.SGD(model_mini_batch.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I1fHORT8LBOK"
   },
   "outputs": [],
   "source": [
    "# Binary Cross Entropy with sigmoid layer\n",
    "criterion = nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z3gdBHHULC7y"
   },
   "outputs": [],
   "source": [
    "model_single_instance = model_single_instance.to(device)\n",
    "model_mini_batch = model_mini_batch.to(device)\n",
    "criterion = criterion.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KF2EdETnLEwt"
   },
   "outputs": [],
   "source": [
    "def binary_accuracy(preds, y):\n",
    "    \"\"\"\n",
    "    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n",
    "    \"\"\"\n",
    "\n",
    "    # round predictions to the closest integer\n",
    "    rounded_preds = torch.round(torch.sigmoid(preds))\n",
    "    correct = (rounded_preds == y).float()  # convert into float for division\n",
    "    acc = correct.sum() / len(correct)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2o9l76H5LGm9"
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def train(model, iterator, optimizer, criterion):\n",
    "\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    for instance in tqdm(iterator, desc=\"Training...\", total=len(iterator)):\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        predictions = model(instance.text)\n",
    "\n",
    "        loss = criterion(predictions, instance.label)\n",
    "\n",
    "        acc = binary_accuracy(predictions, instance.label)\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "\n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bBwRhOrzLKSH"
   },
   "outputs": [],
   "source": [
    "def evaluate(model, iterator, criterion):\n",
    "\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "\n",
    "        for instance in iterator:\n",
    "\n",
    "            predictions = model(instance.text)\n",
    "\n",
    "            loss = criterion(predictions, instance.label)\n",
    "\n",
    "            acc = binary_accuracy(predictions, instance.label)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "\n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FOHkN5P5LMtl"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "\n",
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 487
    },
    "id": "63EPftxxLOxH",
    "outputId": "847dafa0-fc9f-4245-d80c-afb44c52657b"
   },
   "outputs": [],
   "source": [
    "N_EPOCHS = 5\n",
    "\n",
    "best_valid_loss = float(\"inf\")\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    train_loss, train_acc = train(\n",
    "        model_single_instance, train_iterator, optimizer_si, criterion\n",
    "    )\n",
    "    valid_loss, valid_acc = evaluate(model_single_instance, valid_iterator, criterion)\n",
    "\n",
    "    end_time = time.time()\n",
    "\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "\n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model_single_instance.state_dict(), \"tut1-model.pt\")\n",
    "\n",
    "    print(f\"Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s\")\n",
    "    print(f\"\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%\")\n",
    "    print(f\"\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0pmQS2gH14_X",
    "outputId": "a6d8df39-3c9e-4949-e640-91b9099f7506"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...: 100%|██████████| 17500/17500 [00:22<00:00, 770.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Epoch Time: 0m 26s\n",
      "\tTrain Loss: 12.339 | Train Acc: 62.22%\n",
      "\t Val. Loss: 8.236 |  Val. Acc: 62.87%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...: 100%|██████████| 17500/17500 [00:23<00:00, 759.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 02 | Epoch Time: 0m 26s\n",
      "\tTrain Loss: 7.725 | Train Acc: 65.55%\n",
      "\t Val. Loss: 6.985 |  Val. Acc: 67.36%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...: 100%|██████████| 17500/17500 [00:22<00:00, 763.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 03 | Epoch Time: 0m 26s\n",
      "\tTrain Loss: 7.196 | Train Acc: 67.15%\n",
      "\t Val. Loss: 4.812 |  Val. Acc: 71.17%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...: 100%|██████████| 17500/17500 [00:22<00:00, 767.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 04 | Epoch Time: 0m 26s\n",
      "\tTrain Loss: 6.424 | Train Acc: 68.81%\n",
      "\t Val. Loss: 6.351 |  Val. Acc: 69.84%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...: 100%|██████████| 17500/17500 [00:22<00:00, 780.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 05 | Epoch Time: 0m 26s\n",
      "\tTrain Loss: 6.011 | Train Acc: 69.81%\n",
      "\t Val. Loss: 5.491 |  Val. Acc: 74.05%\n"
     ]
    }
   ],
   "source": [
    "N_EPOCHS = 5\n",
    "\n",
    "best_valid_loss = float(\"inf\")\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "\n",
    "    start_time = time.time()\n",
    "    for X, y in train_loader:\n",
    "        train_loss, train_acc = train(\n",
    "            model_mini_batch, train_iterator, optimizer_mb, criterion\n",
    "        )\n",
    "\n",
    "    valid_loss, valid_acc = evaluate(model_mini_batch, valid_iterator, criterion)\n",
    "    end_time = time.time()\n",
    "\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "\n",
    "    # if valid_loss < best_valid_loss:\n",
    "    #     best_valid_loss = valid_loss\n",
    "    #     torch.save(model_single_instance.state_dict(), 'tut1-model.pt')\n",
    "\n",
    "    print(f\"Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s\")\n",
    "    print(f\"\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%\")\n",
    "    print(f\"\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "s2vQBjeTLTTv",
    "outputId": "c2ca37d7-480e-4f9c-f48f-3acd63445eba"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 5.811 | Test Acc: 67.99%\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(\"tut1-model.pt\"))\n",
    "\n",
    "test_loss, test_acc = evaluate(model, test_iterator, criterion)\n",
    "\n",
    "print(f\"Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ev4idwpONzs9",
    "outputId": "6eae601b-e9e0-4cf0-86cd-5b25a536bfed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-2.3597], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor([-3.1945], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor([-8.8104], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor([-7.3358], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor([-21.1220], device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Test of model correctness\n",
    "max_n_test_instances = 5\n",
    "i = 1\n",
    "for instance in valid_iterator:\n",
    "    score = model(instance.text)\n",
    "    print(score)\n",
    "    if i >= max_n_test_instances:\n",
    "        break\n",
    "    else:\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UG6EySjpf_Cv"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "NLP202_hw1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
